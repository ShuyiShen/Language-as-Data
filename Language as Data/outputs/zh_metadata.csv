Publication Date,Time,Author,Title,URL,Text
100,100,100,100,100,100
91,90,27,98,100,99
2019-01-14,22:00:12+08:00,精選書摘,對於未來，我擔心的不是人工智慧像人，而是人像人工智慧,https://www.thenewslens.com/article/157849,寫到這裡，可能有人會問：為什麼非要讓人工智慧像人呢？ 人工智慧對人類世界沒有感受情緒又怎樣？人工智慧自己掌握強大的算力和全新算法，可以發展得比人類更強大，又為什麼要在意與人類交流？人類的愛恨情仇屬於進化的殘留，既原始又低效，人工智慧為什麼要學習呢？它們完全可以不像人也很強大。 這樣想也完全沒問題，而且是很有可能的：它們發展成跟我們不一樣的強大智慧。我們就假設人工智慧未來不屑於獲得人類世界常識，也不關心人類的愛恨情仇，自顧自發展強大，那麼它是不是就沒有任何問題了？ 也不是的。 即便僅考慮它自己，也仍然需要面臨內部調控問題。它可以不建立對世界的統一描述，但它至少需要對自己內部思維有統一調控。 實際上，任何人的心智都不是單一的，每個人的自我都是許多模塊、功能和目標的集合。自我就是對所有模塊的綜合統領。前面講了情緒情感、欲望動機、對他人的感知同情，這裡探討了高級認知的不同層次。而所有這些，都是人這個「大企業」的不同部門，人腦前額葉的功能就是統領好這些部門。 目前的人工智慧一般都是單一功能的，下圍棋、開汽車或者做投資，不同的人工智慧有不一樣的網路結構，沒辦法多功能。如果停留於此，那麼未來人工智慧就是強大的專業工具，不可能成為某種具有特性的新智慧種族。幾乎可以肯定，未來人工智慧的發展肯定不會停留於單一功能，多功能人工智慧的開發，也一定會取得進展。目前，克服前述「遺忘災難」的辦法就是發展多個網路，再進行系統整合。 一旦同一人工智慧開始有多重能力，就會生成多種目標，這些目標不可能同時去追求，就會涉及到目標之間的關係和衝突。不同功能模塊之間的能力和需求可能不一樣，例如追求圍棋取勝的功能模塊需要不斷和自己對弈，而追求語言溝通的模塊卻要一直與更多人對話。最終需要有協調控制機制，讓所有模塊和諧相處。 無論人工智慧是否在意人類，在它們自身心智系統複雜化的過程中，都需要自我調控。不能自我調控的智慧會很容易陷入僵化或瘋狂。單一功能的人工智慧只需要下圍棋，不需要思考「我是否要下圍棋」，但一旦它自身的心智系統包含了很多個功能模塊，就需要在所有目標之間做出選擇。目前人工智慧還由程式師進行目標抉擇，但早晚有一天，它們需要具有抉擇能力。 人工智慧下棋戰勝人類毫不稀奇，但未來，當它的對手是它自己，就需要有高層次決策能力。這是它們未來發展的最大挑戰。 人類在這方面，也並沒有特別好的榜樣經驗。人類心智系統內的衝突往往異常劇烈，而人類常常被這種衝突搞得目瞪口呆。 當你內心中為「失戀」悲痛，非常想好好「吃一頓」安慰自己，你頭腦中卻有另外兩個小人阻撓，一個說「還吃還吃，再胖還得失戀」，另一個說「哭什麼哭，好好學習升職才是正經」，然而悲痛的部分無力地說著「我做不到」，煩躁的部分說「都是因為你活得這麼壓抑才會失戀」。最後會有一個很無奈的仲裁者說：「你們都別吵了，再吵我就抑鬱了。」 這就是我們日常頭腦中上演的多模塊之爭。馬文．明斯基把人的頭腦稱之為「心智社會」，就是說頭腦中的各個「小人兒」就像一個複雜社會一樣嘈嘈雜雜。 不過，儘管我們自己有這麼多混亂的時刻，我們的自我管理能力仍然是機器學習的榜樣。對機器的研究需要反過頭來追問人類，機器研究和人腦研究始終相輔相成向前推進。明斯基把人類的心智系統分成了六層，仔細琢磨起來十分有見地。 按照這種模型，每個人的心智系統都有很多層次，每一層都有「行動者」和「批評者」，行動者給出路徑建議的選項，批評者從自己的角度加以評估質疑。例如當我們想要獲得考試成功，一個頭腦中的行動者建議多做題，相關的批評者會說時間來不及了，另一個頭腦中的行動者建議去偷答案，相關的批評者說違背公德可不行。 其中，沉思一層是我們尋找最優路徑，反思一層是我們質疑自己找到的路對不對，自我反思一層是我們質疑自己能不能找到路徑，自我情感意識一層是問自己到底為什麼這麼做、選擇的意義是什麼。這些批評家讓我們活得專業而審慎。但是如果每一層的批評家都活躍，我們卻又可能會寸步難行。事實上，當我們把頭腦中的批評家關閉一些，行動者會更加冒險，大膽行動，而那是我們感覺最快樂的時候。 重要的是，每一層批評家都根據某些價值評判準則做出評估，若沒有足夠強大的價值評判體系，則很多衝突難以協調和仲裁。有可能模塊與模塊之間缺乏平衡，某一方向過於強大，擠占所有心智資源，讓人陷入偏執；也有可能各個方向過於平衡，沒有精神力量推動，整個體系陷入無法抉擇的心智「糾結」，讓心智崩潰。 對於人類來說，具體任一部分的功能都不需要做到極致，各個功能之間的協調統一才是追求的目標。我們在生活中既不喜歡那些不學無術的愚蠢之人，也不喜歡不懂得生活、只懂讀書的書呆子；既不推崇只會計算、不懂與人交往的自閉症患者，也不推崇只懂察言觀色、毫無真才實學的投機分子。任何一個模塊的缺失都稱為某種心理障礙。我們頭腦中的偶像，總是有勇有謀（既有腎上腺素情緒、又有皮層思考）、敢愛敢恨（情感系統敏銳發達）、志存高遠（動機層次高尚）、俠肝義膽（對他人有同情和幫助），也就是說，一個綜合協調的人。 人類社會生活中，有正確答案的事情不多，有單一目標的事情也不多。而人類的智慧，就在於從事件中提取智慧，在不確定中做出抉擇。 綜合協調各個部分，正是人類大腦最不尋常的智慧。我們現在的人工智慧學習只效仿了一部分皮層的神經網路，做了機器視覺的一些嘗試，還沒有對大腦其他模塊加以學習模擬，這好比是架在空氣中的屋頂，屋頂強大，卻沒有接地的建築支撐。想要實現具有自我調控的綜合腦系統，目前的學習訓練算法遠遠不夠。 對人來說，做出調控和價值評判，需要有穩定卻又靈活的價值觀。一個物種也要有能力自我反思。人類價值觀的傳承和反思通過代際完成。兒童既可以完全繼承父輩文化，也可以形成一種與周圍父輩截然不同的新一代文化。這樣的好處就在於，可以在基因變異速度遠遠跟不上時代發展的情況下，讓種群智慧和文化發生不斷地迭代更新。我們和原始人基因上幾乎沒什麼變化，環境也變化不大，但大腦的適應性讓我們可以快速革新人類文化。 未來，人工智慧如何調節自己內部的多功能模塊，基於什麼做為調控的基本原則，人工智慧總體基於何種原則進行「物種」自我調控，都是人工智慧面臨的大問題。只要是智慧，即便完全和人類不同，也需要面臨智慧最重要的問題：自知、自制、自主。 寫到最後一部分，我們終於該討論一下，未來如果形成超級人工智慧會是什麼樣。 當然這是很遠很遠很遠以後的事情，也不知道會不會有那一天。 對未來的討論，威脅論總是最熱門的。人類對威脅的興奮程度，遠高於歌舞昇平。 目前在人工智慧領域，威脅論的故事版本大概有以下幾個： 一、人工智慧誕生了自我意識，感受到被人欺侮和奴役的痛苦，於是殺人以復仇； 二、人工智慧雖然沒有自我意識，但是頭腦很執拗而異常強大，種番茄的人工智慧會把地球種滿番茄，為此不惜殺滅擋路的人類； 三、超級人工智慧比人類強大太多，像清理蟲子一樣清理人類。 第一個威脅故事，類似於《西方極樂園》或是《人造意識》裡面的描述，我稱之為人工智慧復仇故事；第二個威脅故事，有點像是殘酷版的《瓦力》，可以稱之為人工智慧失控故事；第三個威脅故事，類似於《魔鬼終結者》或是《駭客任務》裡的超級智慧與人對抗，可以稱之為人工智慧壓迫故事。 總結起來，人們對人工智慧發展有兩種猜測，一種是：可能產生一個類人的強人工智慧，因此需要創造出各種適合發展人類心智的學習條件；另一種是就讓人工智慧在現在的數字環境中發展，讓它發展成一個與人類差別很大的超級物種。 第一條路線：擬人路線。 根據前面的分析，想要產生類人的心智，需要的因素包括：身體行動、個體思考、自我認知、社會互動、生存競爭等等。 其中最大的問題在於行動力與思考力之間的衝突。矽基生物的耗能遠在碳基生物之上，電子晶片網路計算速度雖然遠超過人類，但若完成大腦一樣的計算，所消耗的能量是大腦的數億倍。目前算力強大的人工智慧基本採取多晶片、分散式雲計算，AlphaGo戰勝李世乭的時候啟用了一千九百二十個CPU和二百八十個GPU陣列運算。想要給機器人賦予一個獨立的單機大腦，必然需要犧牲大量算力。而既要機器人能行動，又要它會思考，則需要讓機器人做為終端，頭腦與某個強大的運算陣列人工智慧相連接。而這樣的機器人最大的問題在於，聯網的大腦有可能產生獨立的、個體的自我意識和社交特性嗎？令人懷疑。 在類人大小的現實尺度上，行動力、思考力、獨立性，這三種能力可能只能實現其中兩種。缺乏行動力，難以形成具身認知；缺乏思考力，則無法強大；缺乏獨立性，則無法生成自我意識和人際情感。 人類之所以三者兼具，是因為碳基生物耗能更低，碳基大腦活動只需要二十瓦燈泡能量，而人類借由蛋白質分子三維構型做為資訊傳遞工具，形成激素和神經遞質的快捷方式，利用三維資訊，大大簡化了處理過程。人類的大腦算力並不夠，也並不追求極致算力，而是追求在有限的空間資源內完成儘量多的功能。 那麼未來能生成基於碳基的人工智慧嗎？有可能用碳基晶片製造碳基大腦、配一副身軀、製造很多個體行動和群體互動嗎？ 當然可能。恭喜你，你製造出一個人類嬰兒。 另一條路線：非擬人路線。 這是更為可能的一種前景，人工智慧既然是數位化生存的物種，就讓其繼續數位化生存下去。人工智慧會以越來越廣的分散式運算陣列、雲端大數據、智慧聯網的算力，向運算的極限前進。目前全球幾大人工智慧，無論是Siri、「Watson」、還是Bing、Cortana，實際上都依賴於隨時進入互聯網數據庫搜索並調動解答。這樣的智慧從一開始就不局限於與外界無法聯通的軀體內，也不存在思維孤立的大腦。這樣的智慧會越發展越廣，覆蓋面越來越寬泛，它們調用的是全世界的數據，運算結果也同時輸出給全世界用戶。它們幾乎不可能產生人類單一軀體所帶來的欲望、自卑、忠貞等等。它們搜索大數據中的答案，優化各個領域的方案，讓世界更井井有條。它們的算力會越來越強大，但它們並不存在享樂的欲望和對愛的嫉妒。聯網人工智慧的資訊程式也都在雲上有備份，並不存在關機就死亡的威脅，也就沒有對死亡的恐懼。它們無愛無恨，理性計算客觀結果。自由和自主源於個體，欲望與占有源於個體。聯網性雲智慧的思維方式，必然不是弱小個體的思維方式。 分布聯網式人工智慧會不會毀滅人類呢？我們要想到它們的目的。它們不是生物物種，沒有對物理領地的占有性需求。它們生存在人類構建的數字世界中，既沒有軀體感官的享樂，又沒有繁衍的動力。它們可能並不在意人類的欲望，但也沒有自己的欲望。它們總能夠選擇更優的策略。它們可能想要穩定能源的供給，但是想控制電力系統穩定，完全可以直接控制電力系統。任何有目的的毀滅都需要耗能，完全可以由其他更理性的方式達到目的。對它們來說，控制電力系統遠比毀滅人類更容易，也更智慧。 對於未來，我並不太擔心人工智慧和人類的全面對抗，也不擔心人類文明受到根本威脅，但是我擔心人類越來越不重視自身的情感，將自己的一切都劃歸到數字世界，將自己徹底數位化。 人類徹底數位化是指用數字生活代表一切。徹底數位化的一個特徵是認為人的一切可以用他的數據紀錄代表，認為人心只不過就是數字世界中的點讚和購買紀錄。如果是那樣，將不是人工智慧像人，而是人像人工智慧。我們不是數據分析工具，我們是具有血肉軀體的人。體現認知和身體療癒是這些年在心理學領域興起的概念，身體對大腦的意義越來越被重視。大腦是一座城堡，我們每個人的大腦不僅有「思考」的屋頂，還有從身體感受到情感系統的整個堅實的建築。 徹底數位化往往讓我們忽略面對面相處，忽略眼神溝通，忽略淚水、忽略身體的擁抱、忽略失敗的痛苦。但實際上，這些都是我們智慧系統的一部分，最珍貴的一部分。如果我們不再能通過眼神交流，不再懂得數據之外的感情，不認為人生有比利益優化更重要的意義，不再感受得到偉大藝術家給人傳遞的震撼，那我們也就稱不上是萬物之靈，而是把這個位置拱手讓人了。 沒有任何物種能毀滅我們的精神世界，除非我們自己放棄。 這是有關未來我唯一憂慮的事。 本文摘錄自《人之彼岸》，遠流出版 ＊透過以上連結購書，《關鍵評論網》由此所得將全數捐贈兒福聯盟。 1984年生於天津。2006年從北京清華大學物理系畢業，進入北京清華大學天體物理中心；同年，郝景芳正式開始科幻寫作。2013年獲得北京清華大學經濟學博士學位。2017年創立兒童通識教育專案「童行計畫」。 其作品包括短篇小說集《孤獨深處》、長篇小說《流浪蒼穹》、《生於1984》。2016年8月，短篇小說〈北京折疊〉獲得雨果獎最佳中短篇小說（收錄於《孤獨深處》）。 人在此岸，AI在彼岸，對彼岸的遙望讓我們觀照此岸... 〈永生醫院〉 錢睿的母親身患絕症，住進有「妙手回春」美譽的醫院後，竟然奇蹟般地痊癒了。只是，回家後的母親發生了微妙的變化，彷彿是原來的那個母親，又彷彿不是原來的那個母親。他潛入醫院，又雇了私家偵探，想摸清楚醫院的祕密，原來… 〈你在哪裡〉 成功開發人工智慧服務程式「分身」的任毅，事業有成，最大的煩惱就是無暇陪伴愛人。他送這條紫色裙子給素素的時候說：「我不在的時候，讓它給妳安慰。」然而此刻，素素卻大驚失色，差點把拿在手裡的手機掉到地上－－因為任毅的人臉出現在裙子上，而且還在跟她對話… 〈愛的問題〉 林安曾經是人工智慧的代言人、德爾斐公司首席人工智慧工程師。因此，當林安在家中遇刺，變成植物人，只有他發明的人工智慧超級管家陳達出現在命案現場時，所有人都倒吸一口氣… 〈人之島〉 「曾經的」人類回來了。黑暗的星空中，凱克船長帶領著飛船中的人們，穿越黑洞，回到120年前離開的地球。然而，再次醒來，卻看見一名陌生女子，正打算幫他植入腦內晶片…
2,2,35,2,1,2
